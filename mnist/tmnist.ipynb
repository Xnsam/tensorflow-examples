{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\tettu\\python364\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 2 classes.\n",
      "Found 4 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 6s 130ms/step - loss: 0.6966 - acc: 0.4984 - val_loss: 0.6883 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.6671 - acc: 0.6455 - val_loss: 0.5640 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 2s 33ms/step - loss: 0.5845 - acc: 0.7161 - val_loss: 0.3875 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.4449 - acc: 0.8200 - val_loss: 0.2947 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.3027 - acc: 0.8919 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.2435 - acc: 0.9438 - val_loss: 0.1070 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.1638 - acc: 0.9698 - val_loss: 0.4805 - val_acc: 0.7500\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.1094 - acc: 0.9640 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.0413 - acc: 0.9960 - val_loss: 0.6419 - val_acc: 0.7500\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.0509 - acc: 0.9821 - val_loss: 0.0985 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.0276 - acc: 0.9901 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.0320 - acc: 0.9940 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.0174 - acc: 0.9960 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 8.5476e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.0220 - acc: 0.9940 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.0170 - acc: 0.9980 - val_loss: 0.0773 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.0610e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "np.random.seed(123)  \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "\n",
    "batch_size = 10\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        data_format=\"channels_last\",         \n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "def batch_process(dir):\n",
    "        return  image_generator.flow_from_directory(\n",
    "        dir,  # this is the target directory\n",
    "        target_size=(28, 28),  # all images will be resized to 28X28\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "def train_generator():    \n",
    "    return batch_process('images/training')  \n",
    "def validation_generator():\n",
    "    return batch_process('images/testing')\n",
    "\n",
    " \n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "def get_model(retrain):\n",
    "           \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=( 28, 28,1),data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def process_model(retrain):\n",
    "    model=get_model(retrain);\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit_generator(\n",
    "        train_generator(),\n",
    "        steps_per_epoch=500 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator()\n",
    "        )\n",
    "    \n",
    "    \n",
    "    model.save('first_try.h5')\n",
    "    \n",
    "def main():\n",
    "     process_model(False)\n",
    "    \n",
    "     \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
